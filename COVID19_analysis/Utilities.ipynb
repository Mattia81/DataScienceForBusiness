{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Color map for well distributed colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Colors to make every graph costant\n",
    "colorMapWorld = {}\n",
    "\n",
    "\n",
    "colorMapRegions = {}\n",
    "\n",
    "colorMapProvinces = {}\n",
    "\n",
    "\n",
    "\n",
    "def colorMap(states,wrp):\n",
    "    for i in range(len(states)):\n",
    "        color = list(np.random.random( size=3))\n",
    "        color=color.append(1)\n",
    "        if(wrp==0):\n",
    "            colorMapWorld[states[i]]=color\n",
    "            \n",
    "        elif(wrp==1):\n",
    "            colorMapRegions[states[i]]=color\n",
    "        else:\n",
    "            colorMapProvinces[states[i]]=color\n",
    "    \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to plot data about the growth starting from a specific number of cases. The countries for which the values are plotted are passed to the funcion as a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotGrowthDataFromFirstCases(dataset, countries_list, column_reference,\n",
    "                               graph_title, starting_number, y_axis_max_limit = -1):\n",
    "    \"\"\"This procedure allow to plot data relative to the growth of\n",
    "        a specific value starting from the first cases.\n",
    "        Parameters:\n",
    "        dataset -> is the dataset where the data are retreived\n",
    "        countries_list -> is the list of countries which data must be plotted\n",
    "        column_reference -> is the name of the column under analysis\n",
    "        graph_title -> is the name of the graph that must be showed\n",
    "        starting_number -> is the minimum number of cases from each the growth\n",
    "            must be plotted\n",
    "        y_axis_max_limit -> is the maximum value for the y axis plot, default value is -1,\n",
    "            that means plot with the maximum range\n",
    "    \"\"\"\n",
    "    for country in countries_list:\n",
    "        country_growth_total_cases = dataset[dataset['Country'] == country]\n",
    "        country_growth_total_cases = country_growth_total_cases[country_growth_total_cases[column_reference] >= starting_number]\n",
    "        plt.plot(range(len(country_growth_total_cases)),country_growth_total_cases[column_reference],color=colorMapWorld[country], label = country)\n",
    "    plt.xticks(rotation = 90)\n",
    "    plt.legend()\n",
    "    plt.title(graph_title)\n",
    "    if (y_axis_max_limit > 0):\n",
    "        plt.ylim(0, y_axis_max_limit)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to evaluate the number of cases per million of inhabitants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRatePerNumberOfMillion(dataset, ref_column, new_column_name):\n",
    "    \"\"\"This funcion allows to add a new columns to the input dataset\n",
    "       containing the number of cases of the reference column out of the\n",
    "       population.\n",
    "       Parameters:\n",
    "       dataset -> is the input dataset containing all the necessary information.\n",
    "           It is import it has a column \"Population\" with the total number of\n",
    "           inhabitants.\n",
    "       ref_column -> is the column under evaluation\n",
    "       new_column_name -> is the name of the column where the value is stored\n",
    "    \"\"\"\n",
    "    \n",
    "    dataset[new_column_name] = dataset[ref_column]/dataset['Population'] * 1000000\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function that create a new dataframe containing the growth rate for each country. It is possible to specify the time interval to consider, expressed in days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateGrowthRate(dataset, number_of_days, reference_column):\n",
    "    \"\"\"This function allows to evaluate the growth rate of the reference\n",
    "       column in input, gathering the data from the dataset in input with\n",
    "       a specific delay expressed in days. The starting and ending date\n",
    "       considered is based by the minumum and maximum date present in the\n",
    "       input dataset. The dataframe in input must have a column 'Date'\n",
    "       containing the list of reference date. The value returned is a\n",
    "       new dataframe containing for each country a specific column and the\n",
    "       value in each row is the percentage growth calculated from the previous \n",
    "       date.\n",
    "       Parameters:\n",
    "       dataset -> is the dataset to gather the data\n",
    "       number_of_days -> is the frequency in which the evaluation is done\n",
    "       reference_column -> is the column in the dataset in input to consider\n",
    "           for evaluating the growth\n",
    "    \"\"\"\n",
    "    #get the minimum date to consider\n",
    "    minimum_date = dataset['Date'].min()\n",
    "    #get the maximum date to consider\n",
    "    maximum_date = dataset['Date'].max()\n",
    "    #create the list of country to consider\n",
    "    list_of_country = dataset['Country'].unique()\n",
    "    #Create a new dataframe with the list of country in each column\n",
    "    #and the list of date as index\n",
    "    date_list = pd.date_range(start = minimum_date, end = maximum_date, \n",
    "                              freq = str(number_of_days) + 'D')\n",
    "    #create a new dataframe with country as columns and date as index\n",
    "    #filled with 0 values\n",
    "    zero_data = np.zeros(shape=(len(date_list),len(list_of_country)))\n",
    "    df_growth = pd.DataFrame(zero_data, index = date_list, columns = list_of_country)\n",
    "    #iterate on all the index date\n",
    "    for index_date in range(len(date_list)):\n",
    "        #first row is not considered because there is not a previus value\n",
    "        #for which the growth can be evaluated\n",
    "        if index_date == 0:\n",
    "            continue\n",
    "        else:\n",
    "            #get the string date that has to be evaluated\n",
    "            current_date = str(date_list.values[index_date])[:10]\n",
    "            #get the previous date\n",
    "            previous_date = str(date_list.values[index_date - 1])[:10]\n",
    "            #iterate on all the countries present in the input dataset\n",
    "            for country in list_of_country:\n",
    "                #get the list of value available for the country in exam\n",
    "                country_values = dataset.loc[dataset['Country'] == country]\n",
    "                #get the row value for the date/country in exame\n",
    "                current_value = country_values.loc[dataset['Date'] == current_date]\n",
    "                #get the previous row value for the date/country in exame\n",
    "                previous_value = country_values.loc[dataset['Date'] == previous_date]\n",
    "                #verify that the two values are not empty, otherwise skip to the next\n",
    "                #iteration\n",
    "                #get all death\n",
    "                total_value=country_values[reference_column].iloc[-1]\n",
    "                #total_value=country_values.sum[reference_column]\n",
    "                if len(current_value) > 0 and len(previous_value) > 0:\n",
    "                    #if values are not empty, extract the two number used to evaluate\n",
    "                    #the growth\n",
    "                    current_value = current_value[reference_column].values[0]\n",
    "                    previous_value = previous_value[reference_column].values[0]\n",
    "                    \n",
    "                    #verifies that the previous value is not 0 to avoid division error\n",
    "                    if previous_value > 0:\n",
    "                        #evaluate the percentage growth between the 2 consecutive values\n",
    "                        growth_value = (current_value - previous_value) / total_value * 100\n",
    "                        #set the evaluated value in the dataframe, at the right location\n",
    "                        df_growth.loc[current_date,country] = growth_value\n",
    "    #return the new dataframe with the outcomes\n",
    "    return df_growth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to create a matrix of value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matrix_dataset(dataset, column_to_consider):\n",
    "    \"\"\"\n",
    "    This function produce a new dataframe where all the columns\n",
    "    represent a country, each row represent a date and the value\n",
    "    of the matrix is the value specified in the input 'column_to_consider'\n",
    "    Parameters:\n",
    "    dataset -> is the dataset organized in rows\n",
    "    column_to_consider -> is the value contained in the matrix\n",
    "    \"\"\"\n",
    "    #get the minimum date to consider\n",
    "    minimum_date = dataset['Date'].min()\n",
    "    #get the maximum date to consider\n",
    "    maximum_date = dataset['Date'].max()\n",
    "    #create the list of country to consider\n",
    "    country_list = dataset['Country'].unique()\n",
    "    #set Date column as index\n",
    "    dataset.set_index('Date',inplace = True)\n",
    "    #create a new dataframe with the list of country in each column\n",
    "    #and the list of date as index\n",
    "    date_list = pd.date_range(start = minimum_date, end = maximum_date, \n",
    "                              freq = '1' + 'D')\n",
    "    zero_data = np.zeros(dtype=int, shape=(len(date_list),len(country_list)))\n",
    "    df = pd.DataFrame(zero_data, index = date_list, columns = country_list)\n",
    "    for date in date_list:\n",
    "        date = str(date)[:10]\n",
    "        for country in country_list:\n",
    "            date_rows = dataset.loc[dataset['Country'] == country]\n",
    "            try:\n",
    "                value = date_rows.loc[date, column_to_consider]\n",
    "                df.loc[date,country] = value\n",
    "            except:\n",
    "                pass\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to evaluate the moving average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_moving_average(dataset, period, time_series = True):\n",
    "    '''\n",
    "    This function take a time series matrix dataset in input,  \n",
    "    if not it must be present a column 'Date', and a column for each\n",
    "    country. Create a new dataset with the same column but with the\n",
    "    value of each cell that is the average of the previous n value\n",
    "    where n is the period in input. The first n rows of the original\n",
    "    dataset are truncated in the final dataset.\n",
    "    Parameters:\n",
    "    dataset -> input dataset where the moving average is computed.\n",
    "    period -> is the number of sample to evaluate the moving average.\n",
    "    time_serie -> specify if the dataset in input is a time series.\n",
    "    '''\n",
    "    #reset data index if necessary\n",
    "    if time_series:\n",
    "        dataset.reset_index(inplace = True)\n",
    "        dataset.rename(columns = {'index':'Date'}, inplace = True)\n",
    "    \n",
    "    #create a new empty dataframe with a number of rows less of the\n",
    "    #period of time input but with the same country column\n",
    "    date_list = dataset['Date'][period:]\n",
    "    #set Date column as index\n",
    "    dataset.set_index('Date',inplace = True)\n",
    "    country_list = dataset.columns\n",
    "    #create 0 value matrix to insert into the new dataframe\n",
    "    zero_data = np.zeros(dtype=int, shape=(len(date_list),len(country_list)))\n",
    "    df = pd.DataFrame(zero_data, index = date_list, columns = country_list)\n",
    "    \n",
    "    #evaluate the moving average of the input dataset and \n",
    "    #insert the value in the new dataset.\n",
    "    #Iterate on each date\n",
    "    for date_index in range(len(date_list)):\n",
    "        #Iterate on each country\n",
    "        for country in country_list:\n",
    "            #Evaluate the average of the previous n-1 cell and the \n",
    "            #current cell for the country in input\n",
    "            average = dataset.iloc[date_index-period:date_index][country].mean()\n",
    "            #store the average in the new dataset\n",
    "            df.iloc[date_index][country] = average\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot for the lockdown moving average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Inputs:\n",
    "Checks if it's the peak of the curve, or it hasn't reach it yet\n",
    "column-> it's the dataset column we are analyzing. Ex: Afghanistan,Italy ecc...\n",
    "peakIndex-> It's the supposed peak that we have to check\n",
    "\n",
    "Output->\n",
    "It returns 0 if its not the peak yet, otherwise it returns the peak as it is\n",
    "'''\n",
    "def peakChecker(column,peakIndex):\n",
    "    if(peakIndex+datetime.timedelta(days=1) in column.index): #checking if there is a day after the peak\n",
    "        return peakIndex\n",
    "                    \n",
    "                    \n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "\n",
    "      \n",
    "'''\n",
    "10 graphs, one for each country in the top ten with a lockdown line and a counter\n",
    "\n",
    "Inputs:\n",
    "top_ten_moving_average-> the top ten of the countries with the moving mean\n",
    "df_lockdown_states->dataset with the lockdown information\n",
    "df_moving_average_-> dataset with the moving average of every country\n",
    "name-> name of the Y axis of the graph\n",
    "\n",
    "\n",
    "Output->\n",
    "Prints the 10 graphs\n",
    "'''    \n",
    "def plotWithLockdown(top_ten_moving_average,df_lockdown_states,df_moving_average_,name):\n",
    "    i=0 #Subplot indexer, can be from 0 to 4 and indexes the rows\n",
    "    j=0 #Subplot indexer, can be from 0 to 1 and indexes the columns\n",
    "    fig, axs = plt.subplots(5, 2,figsize=(15,20)) #Subplot 5x2 \n",
    "    fig.tight_layout(pad=7.0) #to distanciate better the graphs\n",
    "    \n",
    "    for d in range(0,len(top_ten_moving_average)):\n",
    "        #Calculating the peak of the curve, taking the max value for a column in the top ten\n",
    "        lockdown_date=df_lockdown_states['Beginning Date'][df_lockdown_states['Country']==top_ten_moving_average[d]]\n",
    "        peak=df_moving_average_[top_ten_moving_average[d]].max()\n",
    "        peak=df_moving_average_[top_ten_moving_average[d]][df_moving_average_[top_ten_moving_average[d]]==peak]\n",
    "        \n",
    "        #then checking the peak to see if it's the last value (counter=Peak not reached) or not (counter = lenght between lockdown and peak) \n",
    "        newPeak=peakChecker(df_moving_average_[top_ten_moving_average[d]],peak.index[0])\n",
    "        if(newPeak!=0):\n",
    "            day_counter=len(df_moving_average_[top_ten_moving_average[d]][lockdown_date.iloc[0]:peak.index[0]])\n",
    "        else:\n",
    "            day_counter='Peak not reached yet'\n",
    "\n",
    "        #building the subplots\n",
    "        axs[i, j].plot( df_moving_average_.index,df_moving_average_[top_ten_moving_average[d]],color=colorMapWorld[top_ten_moving_average[d]], label= '')\n",
    "        axs[i, j].set_title(top_ten_moving_average[d])\n",
    "        axs[i, j].set(xlabel='Dates', ylabel=name)\n",
    "        axs[i, j].tick_params(labelrotation=45)\n",
    "        axs[i, j].annotate('Counter from the lockdown: '+str(day_counter), xy=(10, 170), xycoords='axes points',\n",
    "                size=10, ha='left', va='top',\n",
    "                )\n",
    "        try:\n",
    "            axs[i, j].axvline(x=lockdown_date.iloc[0],color='red')\n",
    "        except:\n",
    "            print()\n",
    "       \n",
    "        #Index incrementing. It must be done manually and not with a for otherwise it's impossibile\n",
    "        j=j+1\n",
    "    \n",
    "        if(j==2):\n",
    "            j=0\n",
    "            i=i+1\n",
    "            if(i==5):\n",
    "                i=0\n",
    "'''\n",
    "Output->List containing days passed between lockdown and the peak for each nations, and not just the top ten\n",
    "\n",
    "Input:\n",
    "countires-> list of all countries\n",
    "df_lockdown_states->dataset with the lockdown information\n",
    "df-> dataset with the cases of every country\n",
    "\n",
    "\n",
    "''' \n",
    "\n",
    "def peakDays(countries,df_lockdown_states,df):\n",
    "    days=[]\n",
    "    \n",
    "    \n",
    "    for d in range(0,len(countries)):\n",
    "        #Calculating the peak of the curve, taking the max value for a column in the top ten\n",
    "        lockdown_date=df_lockdown_states['Beginning Date'][df_lockdown_states['Country']==countries[d]]\n",
    "        peak=df[countries[d]].max()\n",
    "        peak=df[countries[d]][df[countries[d]]==peak]\n",
    "        \n",
    "        #then checking the peak to see if it's the last value (counter=Peak not reached) or not (counter = lenght between lockdown and peak) \n",
    "        newPeak=peakChecker(df[countries[d]],peak.index[0])\n",
    "        if(newPeak!=0):\n",
    "            day_counter=len(df[countries[d]][lockdown_date.iloc[0]:peak.index[0]])\n",
    "        else:\n",
    "            day_counter=0\n",
    "        days.append(day_counter)\n",
    "    return days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot creator:\n",
    "This is for the plot for italy's data    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "Input:\n",
    "x-> the range of days passed since the thing we want to represent Ex: if a month passed, x=range(1,30)\n",
    "y-> is an array of datasets row. Each component of the list is a row containing a province/region with \n",
    "the values for the matter in exam following. Ex: if we are analyzing the deaths, every component of the list will be: \n",
    "'Abruzzo,0,20,...,2000' The rows goes on as the same amount of days passed\n",
    "title-> The name given to the graph. It's a list of two elements, cause and effect of the graph. Ex: ['Number of deaths','Region']\n",
    "\n",
    "Output: It prints the graph\n",
    "'''\n",
    "def condition_plot(x,y,title):\n",
    "    plt.figure()\n",
    "    \n",
    "    for i in range(0,len(y)):\n",
    "        if(title[1]=='regions'):\n",
    "            plt.plot(x,y[i][1:],color=colorMapRegions[y[i][0]],label=y[i][0])\n",
    "        else:\n",
    "            plt.plot(x,y[i][1:],color=colorMapProvinces[y[i][0]],label=y[i][0])\n",
    "    plt.legend(bbox_to_anchor=(1, 1.05))\n",
    "\n",
    "\n",
    "    plt.xlabel('Days')\n",
    "    plt.ylabel(title[0])\n",
    "    plt.title(title[0]+' for '+title[1])\n",
    "\n",
    "    plt.show()\n",
    "    plt.clf()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top ten regions/provinces: this is to have a top ten list of regions/provinces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Input:\n",
    "dataset-> it's the dataset in which we have our data to classify\n",
    "name_column-> it's the name/index of the column where the names to assign to each value  is stored. \n",
    "If Abruzzo is the best region for example, we want to use that name, and that name is stored at column '0'\n",
    "\n",
    "Output:\n",
    "A list containing dataset rows, in which we have the region and the values that will be used in the graphs\n",
    "'''\n",
    "\n",
    "def top_ten_list(dataset,name_column):\n",
    "    #loading the list\n",
    "    y=[]  #list of the condition for provinces/regions, in which every entry of the list is a day (its a list of lists)\n",
    "    for i in range(dataset.shape[0]):\n",
    "        y.append(dataset.iloc[i,name_column:]) #position 1 is the province name, which we need for the label in the graph\n",
    "\n",
    "    #Let's start with the top ten \n",
    "    top_ten=[]\n",
    "    last_day=[]\n",
    "    #first let's determine the last day how many people has a certain condition\n",
    "    for i in range(name_column,len(y)):\n",
    "        last_day.append(y[i][-1])\n",
    "    last_day.sort(reverse = True)\n",
    "\n",
    "  \n",
    "    #then let's have only the first 10\n",
    "    for i in range(name_column,len(y)):\n",
    "        if y[i][-1] in last_day[0:10]:\n",
    "            top_ten.append(y[i])\n",
    "    \n",
    "    return top_ten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moving mean italy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Input:\n",
    "data-> Dataset\n",
    "window_size-> The size of the moving mean\n",
    "\n",
    "Output:\n",
    "An array with moving averages for each rows of the dataset\n",
    "'''\n",
    "\n",
    "def moving_mean(data,window_size):\n",
    "    i=0\n",
    "    \n",
    "    moving_averages=[]\n",
    "    while i < len(data) - window_size + 1:\n",
    "        this_window = data[i : i + window_size]\n",
    "        #print(this_window[0][1:])\n",
    "        window_average = sum(this_window[1:]) / window_size\n",
    "        moving_averages.append(window_average)\n",
    "        i += 1\n",
    "\n",
    "    return moving_averages\n",
    "\n",
    "'''\n",
    "Input:\n",
    "top_ten-> list of datasets rows, containg name of the region/provinces and its values\n",
    "window_size-> The size of the moving mean\n",
    "\n",
    "Output:\n",
    "An array with moving averages for each rows of the dataset with the name of the region/province\n",
    "'''\n",
    "\n",
    "def moving_mean_with_names(top_ten,windows_size):\n",
    "\n",
    "    moving_averages=[]\n",
    "    for i in range(len(top_ten)):\n",
    "        moving_averages.append(moving_mean(top_ten[i],windows_size))\n",
    "\n",
    " \n",
    "\n",
    "    for i in range(len(top_ten)):\n",
    "        moving_averages[i][0]=top_ten[i][0]\n",
    "    return moving_averages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autocorrelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "10 graphs, one for each country in the top ten for the autocorrelation\n",
    "\n",
    "Inputs:\n",
    "top_ten_moving_average-> the top ten of the countries with the moving mean\n",
    "\n",
    "df_moving_average_-> dataset with the moving average of every country\n",
    "total-> boolean for total autocorrelation (True) or partial (False)\n",
    "lag-> lag of the autocorrelation plot\n",
    "\n",
    "Output->\n",
    "Prints the 10 graphs\n",
    "'''    \n",
    "def autocorrelationPlot(name,values,lag):\n",
    "    \n",
    "    fig, axs = plt.subplots(1, 2,figsize=(15,5)) #Subplot 5x2 \n",
    "    fig.tight_layout(pad=7.0) #to distanciate better the graphs\n",
    "    values=datasetAlignment(values[name])\n",
    "    \n",
    "    \n",
    "    try:        \n",
    "        plot_acf(values,color=colorMapWorld[name], label= '',lags=lag,ax=axs[0],title=name+\" autocorrelation\")\n",
    "          \n",
    "        plot_pacf(values,color=colorMapWorld[name], label= '',lags=lag,ax=axs[1],title=name+\" partial autocorrelation\")\n",
    "    except:\n",
    "        \n",
    "        plot_acf(values,color=colorMapRegions[name], label= '',lags=lag,ax=axs[0],title=name+\" autocorrelation\")\n",
    "       \n",
    "        plot_pacf(values,color=colorMapRegions[name], label= '',lags=lag,ax=axs[1],title=name+\" partial autocorrelation\")\n",
    "       \n",
    "              \n",
    "        \n",
    "\n",
    "'''\n",
    "\n",
    "Decomposition of the autocorrelation plot\n",
    "'''\n",
    "def decompositionPlot(name,values):\n",
    "  \n",
    "    \n",
    "    \n",
    "        values=datasetAlignment(values[name])\n",
    "        \n",
    "        rcParams['figure.figsize'] = 18, 8\n",
    "        #building the subplots\n",
    "        decomposition=seasonal_decompose(values, model='additive', period=int((len(values)-1)/2),extrapolate_trend='freq')\n",
    "      \n",
    "        fig, axes = plt.subplots(4, 1, sharex=True)\n",
    "        try:\n",
    "        \n",
    "            decomposition.observed.plot(ax=axes[0], legend=False, color=colorMapWorld[name])\n",
    "            axes[0].set_ylabel('Observed')\n",
    "            decomposition.trend.plot(ax=axes[1], legend=False, color=colorMapWorld[name])\n",
    "            axes[1].set_ylabel('Trend')\n",
    "            decomposition.seasonal.plot(ax=axes[2], legend=False, color=colorMapWorld[name])\n",
    "            axes[2].set_ylabel('Seasonal')\n",
    "            decomposition.resid.plot(ax=axes[3], legend=False, color=colorMapWorld[name])\n",
    "            axes[3].set_ylabel('Residual')\n",
    "        except:\n",
    "            decomposition.observed.plot(ax=axes[0], legend=False, color=colorMapRegions[name])\n",
    "            axes[0].set_ylabel('Observed')\n",
    "            decomposition.trend.plot(ax=axes[1], legend=False, color=colorMapRegions[name])\n",
    "            axes[1].set_ylabel('Trend')\n",
    "            decomposition.seasonal.plot(ax=axes[2], legend=False, color=colorMapRegions[name])\n",
    "            axes[2].set_ylabel('Seasonal')\n",
    "            decomposition.resid.plot(ax=axes[3], legend=False, color=colorMapRegions[name])\n",
    "            axes[3].set_ylabel('Residual')\n",
    "        \n",
    "       \n",
    "        \n",
    "            \n",
    "        \n",
    "def datasetAlignment(matrix):\n",
    "    for i in range(0,len(matrix)):\n",
    "        if(matrix[i]>0):\n",
    "            return matrix[i:]\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Linear regression cluster operations\n",
    "\n",
    "Input:\n",
    "x-> indipendent variable\n",
    "y-> dipendent variable\n",
    "labelx and y-> the name of the plot labels\n",
    "\n",
    "output:\n",
    "plot of the regression\n",
    "accuracy informations (R^2 and mean square error)\n",
    "'''\n",
    "\n",
    "\n",
    "def linearRegression(x,y,labelx,labely):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "    regr = LinearRegression().fit(x_train.to_numpy().reshape(-1, 1),y_train)\n",
    "\n",
    "\n",
    "    # Make predictions using the testing set\n",
    "    popDens_y_pred = regr.predict(x_test.to_numpy().reshape(-1, 1))\n",
    "\n",
    "\n",
    "    # The coefficients\n",
    "    print('Coefficients: \\n', regr.coef_)\n",
    "    # The mean squared error\n",
    "    print('Mean squared error: %.2f'\n",
    "          % mean_squared_error(y_test, popDens_y_pred))\n",
    "    # The coefficient of determination: 1 is perfect prediction\n",
    "    print('Coefficient of determination: %.2f'\n",
    "          % r2_score(y_test, popDens_y_pred))\n",
    "\n",
    "    # Plot outputs\n",
    "    plt.scatter(x_test.to_numpy().reshape(-1, 1),y_test,  color='red')\n",
    "    plt.plot(x_test.to_numpy().reshape(-1, 1), popDens_y_pred, color='blue', linewidth=3)\n",
    "    plt.xlabel(labelx)\n",
    "    plt.ylabel(labely)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Counter of deaths until a day X\n",
    "\n",
    "Input:\n",
    "df_matrix_new_cases-> matrix with the number of deaths each day\n",
    "df_regression_friendly-> matrix with the data about days and countries\n",
    "days-> how many days ago from the lockdown\n",
    "\n",
    "Output->number of deaths until day X\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "def numberOfDeathsDayX(df_matrix_new_cases,df_regression_friendly,day):\n",
    "    i=0\n",
    "    numberOfDeaths=[]\n",
    "    for column in df_regression_friendly['Country']:\n",
    "\n",
    "        row=df_matrix_new_cases[df_matrix_new_cases[column].index==pd.to_datetime(df_regression_friendly['Beginning Date'].iloc[i])-datetime.timedelta(days=day)]\n",
    "     \n",
    "        dateToStop=df_matrix_new_cases[:row.index[0]]\n",
    "        \n",
    "      \n",
    "        numberOfDeaths.append(sum(dateToStop[column]))\n",
    "        i=i+1\n",
    "    return numberOfDeaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatterCases(top_ten_new_cases,df_matrix_new_cases,threshold,InOneGraph):\n",
    "    plt.figure(figsize=(15,7.5))\n",
    "\n",
    "    for country in top_ten_new_cases:\n",
    "        for i in range(0,len(df_matrix_new_cases[country])):\n",
    "            if(df_matrix_new_cases[country][i]>threshold):\n",
    "                 matrix=df_matrix_new_cases[country][i:]\n",
    "                 break\n",
    "        x=df_regression_friendly[df_regression_friendly['Country']==country]  \n",
    "        try:\n",
    "            numberOfDaysThreshold=((x['Beginning Date']- matrix.index[0]).iloc[0]).days\n",
    "        except:\n",
    "            numberOfDaysThreshold='n'\n",
    "        if(numberOfDaysThreshold=='n'): \n",
    "            clr='black'\n",
    "        elif(numberOfDaysThreshold<0):\n",
    "            clr='green'\n",
    "        elif(numberOfDaysThreshold>=0 and numberOfDaysThreshold<10):\n",
    "            clr='red'\n",
    "        else:\n",
    "            clr='blue'\n",
    "        if(InOneGraph):\n",
    "            plt.scatter(matrix.index,matrix,color=clr)\n",
    "        else:\n",
    "            plt.scatter(matrix.index,matrix,color=clr)\n",
    "            plt.title(country)\n",
    "            plt.show()\n",
    "            plt.clf()\n",
    "            plt.figure(figsize=(15,7.5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "ARIMA\n",
    "'''\n",
    "\n",
    "\n",
    "def evaluate_arima_model(X, arima_order,trainDim):\n",
    "    # prepare training dataset\n",
    "    train_size = int(len(X) * trainDim)\n",
    "    train, test = X[0:train_size], X[train_size:]\n",
    "    history = [x for x in train]\n",
    "    # make predictions\n",
    "    predictions = list()\n",
    "    for t in range(len(test)):\n",
    "        model = ARIMA(history, order=arima_order)\n",
    "        model_fit = model.fit(disp=0)\n",
    "        yhat = model_fit.forecast()[0]\n",
    "        predictions.append(yhat)\n",
    "        history.append(test[t])\n",
    "    # calculate out of sample error\n",
    "    error = mean_squared_error(test, predictions)\n",
    "    return error\n",
    "\n",
    "def evaluate_sarimax_model(X, arima_order,trainDim):\n",
    "    # prepare training dataset\n",
    "    train_size = int(len(X) * trainDim)\n",
    "    train, test = X[0:train_size], X[train_size:]\n",
    "    history = [x for x in train]\n",
    "    # make predictions\n",
    "    predictions = list()\n",
    "    for t in range(len(test)):\n",
    "        model = SARIMAX(history, order=arima_order)\n",
    "        model_fit = model.fit(disp=0)\n",
    "        yhat = model_fit.forecast()[0]\n",
    "        predictions.append(yhat)\n",
    "        history.append(test[t])\n",
    "    # calculate out of sample error\n",
    "    error = mean_squared_error(test, predictions)\n",
    "    return error\n",
    "# evaluate combinations of p, d and q values for an ARIMA model\n",
    "def evaluate_models(dataset, p_values, d_values, q_values,trainDim,arima):\n",
    "    dataset = dataset.astype('float32')\n",
    "    best_score, best_cfg = float(\"inf\"), None\n",
    "    for p in p_values:\n",
    "        for d in d_values:\n",
    "            for q in q_values:\n",
    "                order = (p,d,q)\n",
    "                if arima:\n",
    "                    try:\n",
    "                        mse = evaluate_arima_model(dataset, order,trainDim)\n",
    "                        if mse < best_score:\n",
    "                            best_score, best_cfg = mse, order\n",
    "                        \n",
    "                    except:\n",
    "                        continue\n",
    "                else:\n",
    "                    try:\n",
    "                        mse = evaluate_sarimax_model(dataset, order,trainDim)\n",
    "                        if mse < best_score:\n",
    "                            best_score, best_cfg = mse, order\n",
    "                       \n",
    "                    except:\n",
    "                        continue\n",
    "                    \n",
    "   \n",
    "    return best_cfg\n",
    "\n",
    "# load dataset\n",
    "def parser(x):\n",
    "    return datetime.strptime('190'+x, '%Y-%m')\n",
    "\n",
    "\n",
    "\n",
    "def autoArima(dataset,trainDim,stationary):\n",
    "    p_values = [4,5,6]\n",
    "    d_values = [0,1,2]\n",
    "    q_values = [2,3,4,5,6]\n",
    "    if (not stationary):\n",
    "        best_cfg=evaluate_models(dataset.values, p_values, d_values, q_values,trainDim,True)\n",
    "        print('ARIMA: ')\n",
    "    else:\n",
    "        best_cfg=evaluate_models(dataset.values, p_values, d_values, q_values,trainDim,False)\n",
    "        \n",
    "        print('SARIMAX: ')\n",
    "        \n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    print(best_cfg)\n",
    "    X = dataset.values\n",
    "    size = int(len(X) * trainDim)\n",
    "    train, test = X[0:size], X[size:len(X)]\n",
    "    history = [x for x in train]\n",
    "    predictions = list()\n",
    "    for t in range(len(test)):\n",
    "        if stationary:\n",
    "            model = SARIMAX(history, order=best_cfg)\n",
    "        else:\n",
    "            model = ARIMA(history, order=best_cfg)\n",
    "    \n",
    "        model_fit = model.fit(disp=0)\n",
    "        output = model_fit.forecast()\n",
    "        yhat = output[0]\n",
    "        predictions.append(yhat)\n",
    "    \n",
    "        obs = test[t]\n",
    "        history.append(obs)\n",
    "        print('predicted=%f, expected=%f' % (yhat, obs))\n",
    "    error = mean_squared_error(test, predictions)\n",
    "\n",
    "    print('Test MSE: %.3f' % error)\n",
    "    # plot\n",
    "    plt.plot(test)\n",
    "    plt.plot(predictions, color='red')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Miscellanous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is when you downlaod the csv files on you pcs file by file.\n",
    "It's no use for this notebook, avoid to compile it, it will not work.\n",
    "There is also scrap code, here in case i need it again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def autocorrelationPlot(top_ten_moving_average,df_moving_average_,total,lag):\n",
    "    i=0 #Subplot indexer, can be from 0 to 4 and indexes the rows\n",
    "    j=0 #Subplot indexer, can be from 0 to 1 and indexes the columns\n",
    "    fig, axs = plt.subplots(5, 2,figsize=(15,20)) #Subplot 5x2 \n",
    "    fig.tight_layout(pad=7.0) #to distanciate better the graphs\n",
    "    \n",
    "    for d in range(0,len(top_ten_moving_average)):\n",
    "        \n",
    "\n",
    "        try:#building the subplots\n",
    "            if(total):\n",
    "                plot_acf(df_moving_average_[top_ten_moving_average[d]],color=colorMapWorld[top_ten_moving_average[d]], label= '',lags=lag,ax=axs[i, j],title=top_ten_moving_average[d]+\" autocorrelation\")\n",
    "            else:\n",
    "                plot_pacf(df_moving_average_[top_ten_moving_average[d]],color=colorMapWorld[top_ten_moving_average[d]], label= '',lags=lag,ax=axs[i, j],title=top_ten_moving_average[d]+\" partial autocorrelation\")\n",
    "        except:\n",
    "            if(total):\n",
    "                plot_acf(df_moving_average_[top_ten_moving_average[d]],color=colorMapRegions[top_ten_moving_average[d]], label= '',lags=lag,ax=axs[i, j],title=top_ten_moving_average[d]+\" autocorrelation\")\n",
    "            else:\n",
    "                plot_pacf(df_moving_average_[top_ten_moving_average[d]],color=colorMapRegions[top_ten_moving_average[d]], label= '',lags=lag,ax=axs[i, j],title=top_ten_moving_average[d]+\" partial autocorrelation\")\n",
    "       \n",
    "                \n",
    "        \n",
    "        j=j+1\n",
    "    \n",
    "        if(j==2):\n",
    "            j=0\n",
    "            i=i+1\n",
    "            if(i==5):\n",
    "                i=0\n",
    "                \n",
    "def decompositionPlot(top_ten_moving_average,df_moving_average_):\n",
    "  \n",
    "    \n",
    "    \n",
    "    for d in range(0,len(top_ten_moving_average)):\n",
    "        \n",
    "        rcParams['figure.figsize'] = 18, 8\n",
    "        #building the subplots\n",
    "        decomposition=seasonal_decompose(df_moving_average_[top_ten_moving_average[d]], model='additive', period=int((len(df_moving_average_)-1)/2))\n",
    "        decomposition.plot()\n",
    "\n",
    "        \n",
    "        fig, axes = plt.subplots(4, 1, sharex=True)\n",
    "        decomposition.observed.plot(ax=axes[0], legend=False, color=colorMapWorld[top_ten_moving_average[d]])\n",
    "        axes[0].set_ylabel('Observed')\n",
    "        decomposition.trend.plot(ax=axes[1], legend=False, color=colorMapWorld[top_ten_moving_average[d]])\n",
    "        axes[1].set_ylabel('Trend')\n",
    "        decomposition.seasonal.plot(ax=axes[2], legend=False, color=colorMapWorld[top_ten_moving_average[d]])\n",
    "        axes[2].set_ylabel('Seasonal')\n",
    "        decomposition.resid.plot(ax=axes[3], legend=False, color=colorMapWorld[top_ten_moving_average[d]])\n",
    "        axes[3].set_ylabel('Residual')\n",
    "        \n",
    "        \n",
    "'''\n",
    "'''\n",
    "print(len(population_time_line_dataset))\n",
    "print(len(time_line_dataset))\n",
    "difference =pd.Index(time_line_dataset['denominazione_provincia'].tolist()).symmetric_difference( population_time_line_dataset['denominazione_provincia'])\n",
    "print(difference)\n",
    "'''\n",
    "\n",
    "'''\n",
    "\n",
    "five_days_before=numberOfDeathsDayX(df_matrix_new_cases,df_regression_friendly,5)\n",
    "data_lockdown=numberOfDeathsDayX(df_matrix_new_cases,df_regression_friendly,0)\n",
    "growth_before_lockdown=(np.asarray(data_lockdown)-np.asarray(five_days_before))/np.asarray(data_lockdown)\n",
    "\n",
    "\n",
    "for filename in listdir(\"./dati-province\\\\\"):\n",
    "   \n",
    "    temp_data= pd.read_csv(\"./\\\\\"+filename)\n",
    "\n",
    "    time_line_dataset[filename[-12:-4]]=temp_data['totale_casi']\n",
    "'''\n",
    "'''\n",
    "df_for_models=pd.DataFrame(df_regression_friendly['Country']).copy()\n",
    "\n",
    "\n",
    "df_for_models['Growth before lockdown']=growth_before_lockdown\n",
    "df_for_models['Growth before lockdown']=df_for_models['Growth before lockdown'].fillna(0)\n",
    "\n",
    "df_for_models\n",
    "\n",
    "df_for_models['Delta growth']=np.asarray(data_lockdown)-np.asarray(five_days_before)\n",
    "df_for_models\n",
    "\n",
    "df_for_models['Lockdown cases']=np.asarray(data_lockdown)\n",
    "df_for_models['5 days before lockdown cases']=np.asarray(five_days_before)\n",
    "df_for_models\n",
    "\n",
    "\n",
    "df_for_models['Growth * Delta']=df_for_models['Growth before lockdown']*df_for_models['Delta growth']\n",
    "df_for_models\n",
    "\n",
    "df_for_models['Peak after lockdown']=peakDays(df_for_models['Country'],df_lockdown,df_matrix_new_cases)\n",
    "df_for_models\n",
    "\n",
    "linearRegression(df_for_models['Growth * Delta'],df_for_models['Peak after lockdown'] ,'Growth * delta','Peak after lockdown')\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dickey-Fuller test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dickeyFuller (series):\n",
    "    adf = adfuller(series)\n",
    "    print('ADF Statistic: {}'.format(adf[0]))\n",
    "    print('p-value: {}'.format(adf[1]))\n",
    "    print('Critical Values:')\n",
    "    for key, value in adf[4].items():\n",
    "        print('\\t{}: {}'.format(key, value))\n",
    "    return adf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Union(lst1, lst2): \n",
    "    final_list = list(set(lst1) | set(lst2)) \n",
    "    return final_list \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def curveAfterPeak(dates,data):\n",
    "    # date format is not suitable for modeling, let's transform the date into incrementals number starting from April 1st\n",
    "  # April 1st is the 37th day of the series\n",
    "    if(data.max()!=data.iloc[-1]):\n",
    "        \n",
    "        starting_date=23\n",
    "        day_numbers = []\n",
    "        plt.figure(figsize=(15,7.5))\n",
    "        for i in range(1, len(dates[window-2:])):\n",
    "            day_numbers.append([i])\n",
    "        X = day_numbers\n",
    "        # # let's train our model only with data after the peak\n",
    "        X = X[starting_date:]\n",
    "        y = data[starting_date:]\n",
    "        # Instantiate Linear Regression\n",
    "        linear_regr = linear_model.LinearRegression()\n",
    "        # Train the model using the training sets\n",
    "        linear_regr.fit(X, y)\n",
    "        plt.scatter(X,y)\n",
    "        print (\"Linear Regression Model Score: %s\" % (linear_regr.score(X, y)))\n",
    "        return X,y,starting_date, linear_regr\n",
    "    else:\n",
    "        print('Peak not reached yet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictTrain(X, Y, TrainX,TrainY,starting_date,listDate, linear_regr):\n",
    "    # convert date of the epidemic peak into datetime format\n",
    "    future_days = 100\n",
    "    date=datetime.datetime.strftime(listDate[starting_date], '%Y-%m-%dT%H:%M:%S')\n",
    "    date_zero = datetime.datetime.strptime(date, '%Y-%m-%dT%H:%M:%S')\n",
    "    # creating x_ticks for making the plot more appealing\n",
    "    date_prev = []\n",
    "    x_ticks = []\n",
    "    step = 5\n",
    "    data_curr = date_zero\n",
    "    x_current = peak_date\n",
    "    n = int(future_days / step)\n",
    "    for i in range(0, n):\n",
    "        date_prev.append(str(data_curr.day) + \"/\" + str(data_curr.month))\n",
    "        x_ticks.append(x_current)\n",
    "        data_curr = data_curr + timedelta(days=step)\n",
    "        x_current = x_current + step\n",
    " \n",
    "    \n",
    "    plt.figure(figsize=(15,7.5))\n",
    "    y_pred = linear_regr.predict(TrainX)\n",
    "    error = max_error(TrainY, y_pred)\n",
    "\n",
    "    X_test = []\n",
    "\n",
    "    for i in range(starting_date, starting_date + future_days):\n",
    "        X_test.append([i])\n",
    "    y_pred_linear = linear_regr.predict(X_test)\n",
    "    y_pred_max = []\n",
    "    y_pred_min = []\n",
    "    for i in range(0, len(y_pred_linear)):\n",
    "        y_pred_max.append(y_pred_linear[i] + error)\n",
    "        y_pred_min.append(y_pred_linear[i] - error)\n",
    "    plt.grid()\n",
    "    plt.scatter(X,Y)\n",
    "    # plot linear regression prediction\n",
    "    plt.plot(X_test, y_pred_linear, color='green', linewidth=2)\n",
    "    # plot maximum error\n",
    "    plt.plot(X_test, y_pred_max, color='red', linewidth=1, linestyle='dashed')\n",
    "    #plot minimum error\n",
    "    plt.plot(X_test, y_pred_min, color='red', linewidth=1, linestyle='dashed')\n",
    "    plt.xlabel('Days')\n",
    "    plt.xlim(starting_date, starting_date + future_days)\n",
    "    plt.xticks(x_ticks, date_prev)\n",
    "\n",
    "\n",
    "    plt.ylabel('new cases')\n",
    "    plt.yscale(\"linear\")\n",
    "    plt.ylim(0, max(TrainY))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
