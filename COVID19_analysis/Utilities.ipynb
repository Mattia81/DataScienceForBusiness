{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Color map for well distributed colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Colors to make every graph costant\n",
    "colorMapWorld = {}\n",
    "\n",
    "'''\n",
    "This funcion allows to add consistent colors on the countries trough the project plots\n",
    "       states -> list of the names of the countries\n",
    "       \n",
    "As output, colorMapWorld will be filled\n",
    "'''\n",
    "\n",
    "def colorMap(states):\n",
    "    for i in range(len(states)):\n",
    "        color = list(np.random.random( size=3))\n",
    "        color.append(1)\n",
    "        colorMapWorld[states[i]]=color\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to plot data about the growth starting from a specific number of cases. The countries for which the values are plotted are passed to the funcion as a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotGrowthDataFromFirstCases(dataset, countries_list, column_reference,\n",
    "                               graph_title, starting_number, y_axis_max_limit = -1):\n",
    "    \"\"\"This procedure allow to plot data relative to the growth of\n",
    "        a specific value starting from the first cases.\n",
    "        Parameters:\n",
    "        dataset -> is the dataset where the data are retreived\n",
    "        countries_list -> is the list of countries which data must be plotted\n",
    "        column_reference -> is the name of the column under analysis\n",
    "        graph_title -> is the name of the graph that must be showed\n",
    "        starting_number -> is the minimum number of cases from each the growth\n",
    "            must be plotted\n",
    "        y_axis_max_limit -> is the maximum value for the y axis plot, default value is -1,\n",
    "            that means plot with the maximum range\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(15,7.5))\n",
    "    for country in countries_list:\n",
    "        country_growth_total_cases = dataset[dataset['Country'] == country]\n",
    "        country_growth_total_cases = country_growth_total_cases[country_growth_total_cases[column_reference] >= starting_number]\n",
    "        plt.plot(range(len(country_growth_total_cases)),country_growth_total_cases[column_reference],color=colorMapWorld[country], label = country)\n",
    "    plt.xticks(rotation = 90)\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.title(graph_title)\n",
    "    if (y_axis_max_limit > 0):\n",
    "        plt.ylim(0, y_axis_max_limit)\n",
    "    plt.xlabel(\"Days from the starting point\")\n",
    "    plt.ylabel(\"Total number\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to evaluate the number of cases per million of inhabitants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRatePerNumberOfMillion(dataset, ref_column, new_column_name):\n",
    "    \"\"\"This funcion allows to add a new columns to the input dataset\n",
    "       containing the number of cases of the reference column out of the\n",
    "       population.\n",
    "       Parameters:\n",
    "       dataset -> is the input dataset containing all the necessary information.\n",
    "           It is import it has a column \"Population\" with the total number of\n",
    "           inhabitants.\n",
    "       ref_column -> is the column under evaluation\n",
    "       new_column_name -> is the name of the column where the value is stored\n",
    "    \"\"\"\n",
    "    \n",
    "    dataset[new_column_name] = dataset[ref_column]/dataset['Population'] * 1000000\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function that create a new dataframe containing the growth rate for each country. It is possible to specify the time interval to consider, expressed in days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateGrowthRate(dataset, number_of_days, reference_column):\n",
    "    \"\"\"This function allows to evaluate the growth rate of the reference\n",
    "       column in input, gathering the data from the dataset in input with\n",
    "       a specific delay expressed in days. The starting and ending date\n",
    "       considered is based by the minumum and maximum date present in the\n",
    "       input dataset. The dataframe in input must have a column 'Date'\n",
    "       containing the list of reference date. The value returned is a\n",
    "       new dataframe containing for each country a specific column and the\n",
    "       value in each row is the percentage growth calculated from the previous \n",
    "       date.\n",
    "       Parameters:\n",
    "       dataset -> is the dataset to gather the data\n",
    "       number_of_days -> is the frequency in which the evaluation is done\n",
    "       reference_column -> is the column in the dataset in input to consider\n",
    "           for evaluating the growth\n",
    "    \"\"\"\n",
    "    #get the minimum date to consider\n",
    "    minimum_date = dataset['Date'].min()\n",
    "    #get the maximum date to consider\n",
    "    maximum_date = dataset['Date'].max()\n",
    "    #create the list of country to consider\n",
    "    list_of_country = dataset['Country'].unique()\n",
    "    #Create a new dataframe with the list of country in each column\n",
    "    #and the list of date as index\n",
    "    date_list = pd.date_range(start = minimum_date, end = maximum_date, \n",
    "                              freq = str(number_of_days) + 'D')\n",
    "    #create a new dataframe with country as columns and date as index\n",
    "    #filled with 0 values\n",
    "    zero_data = np.zeros(shape=(len(date_list),len(list_of_country)))\n",
    "    df_growth = pd.DataFrame(zero_data, index = date_list, columns = list_of_country)\n",
    "    #iterate on all the index date\n",
    "    for index_date in range(len(date_list)):\n",
    "        #first row is not considered because there is not a previus value\n",
    "        #for which the growth can be evaluated\n",
    "        if index_date == 0:\n",
    "            continue\n",
    "        else:\n",
    "            #get the string date that has to be evaluated\n",
    "            current_date = str(date_list.values[index_date])[:10]\n",
    "            #get the previous date\n",
    "            previous_date = str(date_list.values[index_date - 1])[:10]\n",
    "            #iterate on all the countries present in the input dataset\n",
    "            for country in list_of_country:\n",
    "                #get the list of value available for the country in exam\n",
    "                country_values = dataset.loc[dataset['Country'] == country]\n",
    "                #get the row value for the date/country in exame\n",
    "                current_value = country_values.loc[dataset['Date'] == current_date]\n",
    "                #get the previous row value for the date/country in exame\n",
    "                previous_value = country_values.loc[dataset['Date'] == previous_date]\n",
    "                #verify that the two values are not empty, otherwise skip to the next\n",
    "                #iteration\n",
    "                #get all death\n",
    "                total_value=country_values[reference_column].iloc[-1]\n",
    "                #total_value=country_values.sum[reference_column]\n",
    "                if len(current_value) > 0 and len(previous_value) > 0:\n",
    "                    #if values are not empty, extract the two number used to evaluate\n",
    "                    #the growth\n",
    "                    current_value = current_value[reference_column].values[0]\n",
    "                    previous_value = previous_value[reference_column].values[0]\n",
    "                    \n",
    "                    #verifies that the previous value is not 0 to avoid division error\n",
    "                    if previous_value > 0:\n",
    "                        #evaluate the percentage growth between the 2 consecutive values\n",
    "                        growth_value = (current_value - previous_value) / total_value * 100\n",
    "                        #set the evaluated value in the dataframe, at the right location\n",
    "                        df_growth.loc[current_date,country] = growth_value\n",
    "    #return the new dataframe with the outcomes\n",
    "    return df_growth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to create a matrix of value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matrix_dataset(dataset, column_to_consider):\n",
    "    \"\"\"\n",
    "    This function produce a new dataframe where all the columns\n",
    "    represent a country, each row represent a date and the value\n",
    "    of the matrix is the value specified in the input 'column_to_consider'\n",
    "    Parameters:\n",
    "    dataset -> is the dataset organized in rows\n",
    "    column_to_consider -> is the value contained in the matrix\n",
    "    \"\"\"\n",
    "    #get the minimum date to consider\n",
    "    minimum_date = dataset['Date'].min()\n",
    "    #get the maximum date to consider\n",
    "    maximum_date = dataset['Date'].max()\n",
    "    #create the list of country to consider\n",
    "    country_list = dataset['Country'].unique()\n",
    "    #set Date column as index\n",
    "    dataset.set_index('Date',inplace = True)\n",
    "    #create a new dataframe with the list of country in each column\n",
    "    #and the list of date as index\n",
    "    date_list = pd.date_range(start = minimum_date, end = maximum_date, \n",
    "                              freq = '1' + 'D')\n",
    "    zero_data = np.zeros(dtype=int, shape=(len(date_list),len(country_list)))\n",
    "    df = pd.DataFrame(zero_data, index = date_list, columns = country_list)\n",
    "    for date in date_list:\n",
    "        date = str(date)[:10]\n",
    "        for country in country_list:\n",
    "            date_rows = dataset.loc[dataset['Country'] == country]\n",
    "            try:\n",
    "                value = date_rows.loc[date, column_to_consider]\n",
    "                df.loc[date,country] = value\n",
    "            except:\n",
    "                pass\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to evaluate the moving average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_moving_average(dataset, period, time_series = True):\n",
    "    '''\n",
    "    This function take a time series matrix dataset in input,  \n",
    "    if not it must be present a column 'Date', and a column for each\n",
    "    country. Create a new dataset with the same column but with the\n",
    "    value of each cell that is the average of the previous n value\n",
    "    where n is the period in input. The first n rows of the original\n",
    "    dataset are truncated in the final dataset.\n",
    "    Parameters:\n",
    "    dataset -> input dataset where the moving average is computed.\n",
    "    period -> is the number of sample to evaluate the moving average.\n",
    "    time_serie -> specify if the dataset in input is a time series.\n",
    "    '''\n",
    "    #reset data index if necessary\n",
    "    if time_series:\n",
    "        dataset.reset_index(inplace = True)\n",
    "        dataset.rename(columns = {'index':'Date'}, inplace = True)\n",
    "    \n",
    "    #create a new empty dataframe with a number of rows less of the\n",
    "    #period of time input but with the same country column\n",
    "    date_list = dataset['Date'][period:]\n",
    "    #set Date column as index\n",
    "    dataset.set_index('Date',inplace = True)\n",
    "    country_list = dataset.columns\n",
    "    #create 0 value matrix to insert into the new dataframe\n",
    "    zero_data = np.zeros(dtype=int, shape=(len(date_list),len(country_list)))\n",
    "    df = pd.DataFrame(zero_data, index = date_list, columns = country_list)\n",
    "    \n",
    "    #evaluate the moving average of the input dataset and \n",
    "    #insert the value in the new dataset.\n",
    "    #Iterate on each date\n",
    "    for date_index in range(len(date_list)):\n",
    "        #Iterate on each country\n",
    "        for country in country_list:\n",
    "            #Evaluate the average of the previous n-1 cell and the \n",
    "            #current cell for the country in input\n",
    "            average = dataset.iloc[date_index-period:date_index][country].mean()\n",
    "            #store the average in the new dataset\n",
    "            df.iloc[date_index][country] = average\n",
    "    return df\n",
    "\n",
    "'''\n",
    "Input:\n",
    "data-> Dataset\n",
    "window_size-> The size of the moving mean\n",
    "\n",
    "Output:\n",
    "An array with moving averages for each rows of the dataset\n",
    "'''\n",
    "\n",
    "def moving_mean(data,window_size):\n",
    "    i=0\n",
    "    \n",
    "    moving_averages=[]\n",
    "    while i < len(data) - window_size + 1:\n",
    "        this_window = data[i : i + window_size]\n",
    "        #print(this_window[0][1:])\n",
    "        window_average = sum(this_window[1:]) / window_size\n",
    "        moving_averages.append(window_average)\n",
    "        i += 1\n",
    "\n",
    "    return moving_averages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot for the lockdown moving average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Inputs:\n",
    "Checks if it's the peak of the curve, or it hasn't reach it yet\n",
    "column-> it's the dataset column we are analyzing. Ex: Afghanistan,Italy ecc...\n",
    "peakIndex-> It's the supposed peak that we have to check\n",
    "\n",
    "Output->\n",
    "It returns 0 if its not the peak yet, otherwise it returns the peak as it is\n",
    "'''\n",
    "def peakChecker(column,peakIndex):\n",
    "    if(peakIndex+datetime.timedelta(days=1) in column.index): #checking if there is a day after the peak\n",
    "        return peakIndex\n",
    "                    \n",
    "                    \n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "\n",
    "      \n",
    "'''\n",
    "A certain number of graphs, one for each country in the top ten/list of country we use as a parameter\n",
    "with a lockdown line and a counter\n",
    "\n",
    "Inputs:\n",
    "top_ten-> the top ten/list of the countries \n",
    "df_lockdown_states->dataset with the lockdown information\n",
    "df-> dataset with the features\n",
    "name-> name of the Y axis of the graph\n",
    "\n",
    "\n",
    "Output->\n",
    "Prints the  graphs\n",
    "'''    \n",
    "def plotWithLockdown(top_ten,df_lockdown_states,df,name):\n",
    "    i=0 #Subplot indexer, can be from 0 to 4 and indexes the rows\n",
    "    j=0 #Subplot indexer, can be from 0 to 1 and indexes the columns\n",
    "    graphs=int(len(top_ten)/2)\n",
    "    if(len(top_ten)%2==1):\n",
    "        graphs=int(len(top_ten)/2)+1\n",
    "    fig, axs = plt.subplots(graphs, 2,figsize=(15,20)) #Subplot 5x2\n",
    "    if(len(top_ten)%2==1):\n",
    "        fig.delaxes(axs[graphs-1,1]) #if there are no even number of countries, we procede to make an odd number of graphs\n",
    "    fig.tight_layout(pad=7.0) #to distanciate better the graphs\n",
    "    country,peaks,ndaysPeak,lockdown,ndaysLock=statTable(df,df_lockdown_states)\n",
    "    for d in range(0,len(top_ten)):\n",
    "        #Calculating the peak of the curve, taking the max value for a column in the top ten\n",
    "        \n",
    "        lockdown_date=df_lockdown_states['Beginning Date'][df_lockdown_states['Country']==top_ten[d]]\n",
    "        \n",
    "        index=country.index(top_ten[d])\n",
    "        peak=peaks[index]\n",
    "        lock=lockdown[index]\n",
    "        if(peak!=0):\n",
    "            day_counter=ndaysPeak[index]\n",
    "        else:\n",
    "            day_counter='Peak not reached yet'\n",
    "        if(lock!=0):\n",
    "            lock_counter=ndaysLock[index]\n",
    "        else:\n",
    "            lock_counter='Lockdown not present'\n",
    "        #building the subplots\n",
    "        axs[i, j].plot( df.index,df[top_ten[d]],color=colorMapWorld[top_ten[d]], label= '')\n",
    "        axs[i, j].set_title(top_ten[d])\n",
    "        axs[i, j].set(xlabel='Dates', ylabel=name)\n",
    "        axs[i, j].tick_params(labelrotation=45)\n",
    "        axs[i, j].annotate('Counter from the 200 to the lockdown: '+str(lock_counter), xy=(10, 170), xycoords='axes points',\n",
    "                size=10, ha='left', va='top',\n",
    "                )\n",
    "        axs[i, j].annotate('Counter from the 200 to the peak: '+str(day_counter), xy=(10, 150), xycoords='axes points',\n",
    "                size=10, ha='left', va='top',\n",
    "                )\n",
    "        try:\n",
    "            axs[i, j].axvline(x=lockdown_date.iloc[0],color='red')\n",
    "        except:\n",
    "            print()\n",
    "       \n",
    "        #Index incrementing. It must be done manually and not with a for otherwise it's impossibile\n",
    "        j=j+1\n",
    "    \n",
    "        if(j==2):\n",
    "            j=0\n",
    "            i=i+1\n",
    "            if(i==graphs):\n",
    "                i=0\n",
    "\n",
    "'''\n",
    "A function that calculates the number of days between the peak and the 200 days and between lockdown  and the 200 days mark\n",
    "\n",
    "Inputs:\n",
    "df_matrix-> features to use to calculate the point in time of the 200 days\n",
    "df_lockdown-> dates of the lockdowns\n",
    "\n",
    "\n",
    "Output->\n",
    "    country_list-> list of the countires\n",
    "    peaks-> 0 and 1 if the peak is reached or not \n",
    "    ndaysPeak-> number of days between 200 days and the peak date\n",
    "    lockdown-> 0 and 1 if the lockdown is reached or not \n",
    "    ndaysLock-> number of days between 200 days and the lockdown\n",
    "    \n",
    "'''                  \n",
    "def statTable(df_matrix,df_lockdown):\n",
    "    country_list=[]\n",
    "    beg_list=[]\n",
    "    peaks=[]\n",
    "    ndaysPeak=[]\n",
    "    lockdown=[]\n",
    "    ndaysLock=[]\n",
    "    for country in df_matrix.columns:\n",
    "        for i in range(0,len(df_matrix[country])):\n",
    "            if(df_matrix[country][i]>200): #check when we overcome the 200 mark in the feature and memorize the date\n",
    "                country_list.append(country)\n",
    "                beg_date=df_matrix.index[i]\n",
    "                beg_list.append(beg_date)\n",
    "                peak_date=df_matrix[df_matrix[country]==df_matrix[country].max()].index\n",
    "                try:  #checking if the peak is reached yet\n",
    "                    df_matrix.loc[peak_date+ timedelta(days=1)]\n",
    "                    peak=1\n",
    "                    \n",
    "                except:\n",
    "                    peak=0\n",
    "                    \n",
    "                peaks.append(peak)    \n",
    "                if(peak==1):  #if the peak is present, we count the days, otherwise we count them until today\n",
    "                    ndaysPeak.append(((peak_date-beg_date).days)[0])\n",
    "                else:\n",
    "                    ndaysPeak.append(((datetime.datetime.strptime('2020-05-20', \"%Y-%m-%d\")-beg_date).days))\n",
    "\n",
    "                try: #checking if the lockdown is reached yet\n",
    "                    a=df_lockdown[df_lockdown['Country']==country]\n",
    "                    datetime.datetime.strftime(a['Beginning Date'].iloc[0], \"%Y-%m-%d\")\n",
    "                    lock=1\n",
    "                    \n",
    "                except:\n",
    "                    lock=0\n",
    "                    \n",
    "                lockdown.append(lock)\n",
    "                if(lock==1): #if the lockdown is present, we count the days, otherwise we count them until today\n",
    "                    ndaysLock.append(((a['Beginning Date'].iloc[0]-beg_date).days))\n",
    "                else:\n",
    "                    ndaysLock.append(((datetime.datetime.strptime('2020-05-20', \"%Y-%m-%d\")-beg_date).days))\n",
    "\n",
    "                \n",
    "                \n",
    "                break\n",
    "    return country_list,peaks,ndaysPeak,lockdown,ndaysLock\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "Output->List containing days passed between lockdown and the peak for each nations, and not just the top ten\n",
    "\n",
    "Input:\n",
    "countires-> list of all countries\n",
    "df_lockdown_states->dataset with the lockdown information\n",
    "df-> dataset with the cases of every country\n",
    "\n",
    "\n",
    "''' \n",
    "\n",
    "def peakDays(countries,df_lockdown_states,df):\n",
    "    days=[]\n",
    "    \n",
    "    \n",
    "    for d in range(0,len(countries)):\n",
    "        #Calculating the peak of the curve, taking the max value for a column in the top ten\n",
    "        lockdown_date=df_lockdown_states['Beginning Date'][df_lockdown_states['Country']==countries[d]]\n",
    "        peak=df[countries[d]].max()\n",
    "        peak=df[countries[d]][df[countries[d]]==peak]\n",
    "        \n",
    "        #then checking the peak to see if it's the last value (counter=Peak not reached) or not (counter = lenght between lockdown and peak) \n",
    "        newPeak=peakChecker(df[countries[d]],peak.index[0])\n",
    "        if(newPeak!=0):\n",
    "            day_counter=len(df[countries[d]][lockdown_date.iloc[0]:peak.index[0]])\n",
    "        else:\n",
    "            day_counter=0\n",
    "        days.append(day_counter)\n",
    "    return days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autocorrelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "10 graphs, one for each country in the top ten for the autocorrelation\n",
    "\n",
    "Inputs:\n",
    "name-> list of the countries\n",
    "\n",
    "values_-> dataset with the data of every country\n",
    "lag-> lag of the autocorrelation plot\n",
    "\n",
    "Output->\n",
    "Prints the 10 graphs\n",
    "'''    \n",
    "def autocorrelationPlot(name,values_,lag):\n",
    "    \n",
    "    values = values_.copy()\n",
    "    fig, axs = plt.subplots(1, 2,figsize=(15,5)) #Subplot 5x2 \n",
    "    fig.tight_layout(pad=7.0) #to distanciate better the graphs\n",
    "    values=datasetAlignment(values[name])\n",
    "    \n",
    "    \n",
    "    try:        \n",
    "        plot_acf(values,color=colorMapWorld[name], label= '',lags=lag,ax=axs[0],title=name+\" autocorrelation\")\n",
    "          \n",
    "        plot_pacf(values,color=colorMapWorld[name], label= '',lags=lag,ax=axs[1],title=name+\" partial autocorrelation\")\n",
    "    except:\n",
    "        \n",
    "        plot_acf(values,color=colorMapRegions[name], label= '',lags=lag,ax=axs[0],title=name+\" autocorrelation\")\n",
    "       \n",
    "        plot_pacf(values,color=colorMapRegions[name], label= '',lags=lag,ax=axs[1],title=name+\" partial autocorrelation\")\n",
    "       \n",
    "              \n",
    "        \n",
    "\n",
    "'''\n",
    "\n",
    "Decomposition of the autocorrelation plot\n",
    "\n",
    "Inputs:\n",
    "name-> list of the countries\n",
    "\n",
    "values_-> dataset with the data of every country\n",
    "\n",
    "Output->\n",
    "Prints the plots\n",
    "'''\n",
    "def decompositionPlot(name, values_):\n",
    "\n",
    "        values = values_.copy()\n",
    "        \n",
    "        values=datasetAlignment(values[name])\n",
    "        \n",
    "        rcParams['figure.figsize'] = 18, 8\n",
    "        #building the subplots\n",
    "        decomposition=seasonal_decompose(values, model='additive', period=int((len(values)-1)/2),extrapolate_trend='freq')\n",
    "      \n",
    "        fig, axes = plt.subplots(4, 1, sharex=True)\n",
    "        decomposition.observed.plot(ax=axes[0], legend=False, color=colorMapWorld[name])\n",
    "        axes[0].set_ylabel('Observed')\n",
    "        decomposition.trend.plot(ax=axes[1], legend=False, color=colorMapWorld[name])\n",
    "        axes[1].set_ylabel('Trend')\n",
    "        decomposition.seasonal.plot(ax=axes[2], legend=False, color=colorMapWorld[name])\n",
    "        axes[2].set_ylabel('Seasonal')\n",
    "        decomposition.resid.plot(ax=axes[3], legend=False, color=colorMapWorld[name])\n",
    "        axes[3].set_ylabel('Residual')\n",
    "        \n",
    "       \n",
    "        \n",
    "'''\n",
    "Remove the 0 values from the matrix and start from the \"beginning date\" where the new deaths/cases etc. starts to grow for the \n",
    "first time\n",
    "\n",
    "Inputs:\n",
    "matrix-> features for a country\n",
    "\n",
    "\n",
    "\n",
    "Output->\n",
    "matrix without the 0 values at the beginning\n",
    "\n",
    "'''            \n",
    "        \n",
    "def datasetAlignment(matrix):\n",
    "    for i in range(0,len(matrix)):\n",
    "        if(matrix[i]>0):\n",
    "            return matrix[i:]\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Linear regression cluster operations\n",
    "\n",
    "Input:\n",
    "x-> indipendent variable\n",
    "y-> dipendent variable\n",
    "labelx and y-> the name of the plot labels\n",
    "\n",
    "output:\n",
    "plot of the regression\n",
    "accuracy informations (R^2 and mean square error)\n",
    "'''\n",
    "\n",
    "\n",
    "def linearRegression(x,y,labelx,labely):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "    regr = LinearRegression().fit(x_train.to_numpy().reshape(-1, 1),y_train)\n",
    "\n",
    "\n",
    "    # Make predictions using the testing set\n",
    "    popDens_y_pred = regr.predict(x_test.to_numpy().reshape(-1, 1))\n",
    "\n",
    "\n",
    "    # The coefficients\n",
    "    print('Coefficients: \\n', regr.coef_)\n",
    "    # The mean squared error\n",
    "    print('Mean squared error: %.2f'\n",
    "          % mean_squared_error(y_test, popDens_y_pred))\n",
    "    # The coefficient of determination: 1 is perfect prediction\n",
    "    print('Coefficient of determination: %.2f'\n",
    "          % r2_score(y_test, popDens_y_pred))\n",
    "\n",
    "    # Plot outputs\n",
    "    plt.figure(figsize=(15,7.5))\n",
    "    plt.scatter(x_test.to_numpy().reshape(-1, 1),y_test,  color='red')\n",
    "    plt.plot(x_test.to_numpy().reshape(-1, 1), popDens_y_pred, color='blue', linewidth=3)\n",
    "    plt.xlabel(labelx)\n",
    "    plt.ylabel(labely)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dickey-Fuller test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Dicky fuller test\n",
    "\n",
    "Input:\n",
    "series->the time series in input\n",
    "\n",
    "output:\n",
    " the dicky fuller test results\n",
    "'''\n",
    "def dickeyFuller (series):\n",
    "    adf = adfuller(series)\n",
    "    print('ADF Statistic: {}'.format(adf[0]))\n",
    "    print('p-value: {}'.format(adf[1]))\n",
    "    print('Critical Values:')\n",
    "    for key, value in adf[4].items():\n",
    "        print('\\t{}: {}'.format(key, value))\n",
    "    return adf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression for the part after the peak of the pandemic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "It pritns a plot to show how the data are flowing after the peak\n",
    "\n",
    "Input:\n",
    "dates-> list of all the dates from the beginning of the pandemic until today\n",
    "data-> the features like new cases or deaths\n",
    "country_name-> name of the country to plot in the graph title\n",
    "\n",
    "output:\n",
    "a plot with the linear regression of the curve \n",
    "X-> list of the number od days (a range)\n",
    "y-> the features starting from the same data of the first element of X\n",
    "starting date-> the number conversion of the data when the peak was reached\n",
    "linear_regr-> linear regression of the curve\n",
    "'''\n",
    "def curveAfterPeak(dates,data, country_name):\n",
    "    # date format is not suitable for modeling,so it's better to transform it into a number\n",
    "    #For example, the first day of the peak in italy was reached around mid march, which is the 23th day from when the pandemic \n",
    "    #started in italy. Here we are doing that conversion\n",
    "    if(data.max()!=data.iloc[-1]):\n",
    "       \n",
    "        for i in range(len(data)):\n",
    "            if(data[i]==data.max()):\n",
    "                starting_date=i\n",
    "                break\n",
    "       \n",
    "        day_numbers = []\n",
    "        plt.figure(figsize=(15,7.5))\n",
    "        for i in range(1, len(dates[window-2:])):\n",
    "            day_numbers.append([i])\n",
    "        X = day_numbers\n",
    "        # # let's train our model only with data after the peak\n",
    "        X = X[starting_date:]\n",
    "        y = data[starting_date:]\n",
    "        # Instantiate Linear Regression\n",
    "        linear_regr = linear_model.LinearRegression()\n",
    "        # Train the model using the training sets\n",
    "        linear_regr.fit(X, y)\n",
    "        plt.scatter(X,y)\n",
    "        plt.xlabel(\"Number of days from the first day with 200 new confirmed cases\")\n",
    "        plt.ylabel(\"Number of new confirmed cases\")\n",
    "        plt.title(country_name + \" - Linear regression model\")\n",
    "        plt.plot(X, linear_regr.predict(X), color ='red')\n",
    "        print (\"Linear Regression Model Score:\", \"{:.2f}\".format((linear_regr.score(X, y))))\n",
    "        return X,y,starting_date, linear_regr\n",
    "    else:\n",
    "        print('Peak not reached yet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "It prints a plot in logaritmic scale where we can see the prediction of the pandemic for a country, and see\n",
    "when it will reach 0 with a certain confidence interval\n",
    "\n",
    "Input:\n",
    "X-> list of the number of days (a range)\n",
    "y-> the features starting from the same data of the first element of X\n",
    "TrainX-> list of the number of days (a range) used to make a predictionon the data\n",
    "TrainY-> the features starting from the same data of the first element of X used to make the error from the prediction and the acutal data\n",
    "starting date-> the number conversion of the data when the peak was reached\n",
    "linear_regr-> linear regression of the curve\n",
    "listDate-> the list of dates in their usual format\n",
    "y_test-> the data that we use for testing of the future days we want to predict\n",
    "prediction_days-> a parameter to enlarge or reduce the final plot of a certain amount of days\n",
    "country_name-> name of the country to plot in the graph title\n",
    "\n",
    "output:\n",
    "a plot with the curve reaching 0\n",
    "R^2 of the prediction\n",
    "\n",
    "'''\n",
    "\n",
    "def predictTrain(X, Y, TrainX,TrainY,starting_date,listDate, linear_regr,y_test,prediction_days, country_name):\n",
    "    # convert date of the epidemic peak into datetime format\n",
    "    future_days = prediction_days\n",
    "    date=datetime.datetime.strftime(listDate[starting_date], '%Y-%m-%dT%H:%M:%S')\n",
    "    date_zero = datetime.datetime.strptime(date, '%Y-%m-%dT%H:%M:%S')\n",
    "    # creating x_ticks to make the plot more appealing\n",
    "    date_prev = []\n",
    "    x_ticks = []\n",
    "    step = 5\n",
    "    data_curr = date_zero\n",
    "    x_current = peak_date\n",
    "    n = int(future_days / step)\n",
    "    for i in range(0, n): #strings that will be used on the ticks of the plot, converting the number of days in the actual date\n",
    "        date_prev.append(str(data_curr.day) + \"/\" + str(data_curr.month))\n",
    "        x_ticks.append(x_current)\n",
    "        data_curr = data_curr + timedelta(days=step)\n",
    "        x_current = x_current + step\n",
    " \n",
    "    \n",
    "    plt.figure(figsize=(15,7.5))\n",
    "    y_pred = linear_regr.predict(TrainX)\n",
    "    error = max_error(TrainY, y_pred)\n",
    "\n",
    " \n",
    "\n",
    "    X_test = []\n",
    "\n",
    " \n",
    "\n",
    "    for i in range(starting_date, starting_date + future_days):\n",
    "        X_test.append([i])\n",
    "        \n",
    "    \n",
    "    y_pred_linear = linear_regr.predict(X_test)\n",
    "    y_pred_max = []\n",
    "    y_pred_min = []\n",
    "    for i in range(0, len(y_pred_linear)):\n",
    "        y_pred_max.append(y_pred_linear[i] + error)\n",
    "        y_pred_min.append(y_pred_linear[i] - error)\n",
    "    plt.grid()\n",
    "    plt.scatter(X,Y)\n",
    "    # plot linear regression prediction\n",
    "    plt.plot(X_test, y_pred_linear, color='green', linewidth=2)\n",
    "    # plot maximum error\n",
    "    plt.plot(X_test, y_pred_max, color='red', linewidth=1, linestyle='dashed')\n",
    "    #plot minimum error\n",
    "    plt.plot(X_test, y_pred_min, color='red', linewidth=1, linestyle='dashed')\n",
    "    plt.xlim(starting_date, starting_date + future_days)\n",
    "    plt.xticks(x_ticks, date_prev)\n",
    "   \n",
    "    print(\"Prediction score:\", \"{:.2f}\".format(r2_score(y_test,y_pred_linear[len(TrainY):len(TrainY)+len(y_test)])))\n",
    "\n",
    " \n",
    "    plt.xlabel(\"Dates\")\n",
    "    plt.ylabel(\"Number of new confirmed cases\")\n",
    "    plt.title(country_name + \" - 0 new confirmed cases prediction\")\n",
    "    plt.yscale(\"log\")\n",
    "    plt.ylim(0, max(TrainY))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time series analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_stationarity(df_timeseries):\n",
    "    \"\"\"\n",
    "    Check Stationariety of time series.\n",
    "    Please use np.array or pd.series as Input with your TS data only\n",
    "    \"\"\"\n",
    "    #Convert numpy array to pandas serie\n",
    "    if type(df_timeseries) is np.ndarray:\n",
    "        df_timeseries = pd.Series(df_timeseries) \n",
    "        \n",
    "    try:\n",
    "        #Determing rolling statistics\n",
    "        rolmean = df_timeseries.rolling(window=12).mean()\n",
    "        rolstd = df_timeseries.rolling(window=12).std()\n",
    "\n",
    "        #Plot rolling statistics:\n",
    "        orig = plt.plot(df_timeseries, color='blue',label='Original')\n",
    "        mean = plt.plot(rolmean, color='red', label='Rolling Mean')\n",
    "        std = plt.plot(rolstd, color='black', label = 'Rolling Std')\n",
    "        plt.legend(loc='best')\n",
    "        plt.title('Rolling Mean & Standard Deviation')\n",
    "        plt.show(block=False)\n",
    "\n",
    "        #Perform Dickey-Fuller test:\n",
    "        print('Results of Dickey-Fuller Test:')\n",
    "\n",
    "        dftest = adfuller(df_timeseries, autolag='AIC')\n",
    "        dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n",
    "        for key,value in dftest[4].items():\n",
    "            dfoutput['Critical Value (%s)'%key] = value\n",
    "        \n",
    "        # print(dfoutput)\n",
    "    \n",
    "        return dftest, dfoutput\n",
    "    except Exception as message:\n",
    "        print(f\"Impossible to calc the stationariery of your TS: {message}\")\n",
    "        return None, None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
